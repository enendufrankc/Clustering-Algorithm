{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1975f713",
   "metadata": {},
   "source": [
    "Objectives \n",
    "This assignment requires you to implement various clustering algorithms using the Python programming language and apply them to cluster a given dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c7d0db",
   "metadata": {},
   "source": [
    "Assignment description \n",
    "In the assignment, you are required to cluster words. The words are stored in a file that you will find in the archive CA2data.zip. The first entry in each line is a word followed by 300 features (word embedding) describing the meaning of that word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a7b3a",
   "metadata": {},
   "source": [
    "Questions/Tasks \n",
    "1. (20 marks) Explain the k-means clustering algorithm. Provide pseudo code of the algorithm. It should be the version of the k-means clustering algorithm discussed in the lectures. Implement the k-means clustering algorithm following your explanation and the pseudo code. In the implementation, select initial cluster representatives randomly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c750e",
   "metadata": {},
   "source": [
    "a. Explain the k-means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b4065",
   "metadata": {},
   "source": [
    "The K-means clustering algorithm is a method for dividing a dataset into K clusters. The algorithm starts with an initial guess for the K cluster centers, and then iteratively assigns each data point to its closest cluster center, followed by updating the cluster centers to be the mean of the assigned points. This process continues until the cluster centers stop moving or until a maximum number of iterations is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fa9e0",
   "metadata": {},
   "source": [
    "b. Provide pseudo code of the algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40e21fd7",
   "metadata": {},
   "source": [
    "K-Means Clustering Algorithm:\n",
    "------------------------------\n",
    "\n",
    "Inputs:\n",
    "- K: number of clusters\n",
    "- Dataset: array of points {X1, ..., Xn}\n",
    "\n",
    "Outputs:\n",
    "- Cluster representatives: array of points {Y1, ..., Yk}\n",
    "\n",
    "1. Initialization phase:\n",
    "   - Choose K cluster representatives Y1, ..., Yk from the dataset randomly\n",
    "\n",
    "2. Assignment phase:\n",
    "   - For each point X in the dataset, find the closest cluster representative Y_j based on squared Euclidean distance\n",
    "   - Assign X to the cluster with representative Y_j\n",
    "   - Store the resulting clusters C1, ..., Ck\n",
    "\n",
    "3. Optimization phase:\n",
    "   - Compute the new cluster representatives Y1, ..., Yk as the means of the points in each cluster C1, ..., Ck\n",
    "\n",
    "4. Repeat assignment and optimization phases until convergence:\n",
    "   - If no points have changed clusters, break\n",
    "   - If maximum number of iterations is reached, break\n",
    "   - Otherwise, repeat assignment and optimization phases\n",
    "\n",
    "5. Return the cluster representatives Y1, ..., Yk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e665db9",
   "metadata": {},
   "source": [
    "c. Implement the k-means clustering algorithm following your explanation and the pseudo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0aeb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3a2db",
   "metadata": {},
   "source": [
    "2. (20 marks) Explain the k-means++ clustering algorithm. Provide pseudo code of the algorithm. It should be the version of the k-means++ clustering algorithm discussed in the lectures. Implement the k-means++ clustering algorithm following your explanation and the pseudo code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ccd4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed28ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4e2a05",
   "metadata": {},
   "source": [
    "3. (20 marks) Explain the Bisecting k-Means hierarchical clustering algorithm. Provide pseudo code of the algorithm. It should be the version of the Bisecting k-Means clustering algorithm discussed in the lectures. Implement the Bisecting k-Means algorithm following your explanation and the pseudo code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3b146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e8455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7ac80a",
   "metadata": {},
   "source": [
    "4. (10 marks) Run the k-means clustering algorithm you implemented in part (1) to cluster the given instances. Vary the value of kfrom 1 to 9 and compute the Silhouette coefficient for each set of clusters. Plot kin the horizontal axis and the Silhouette coefficient in the vertical axis in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668b877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a8aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "234ce070",
   "metadata": {},
   "source": [
    "5. (10 marks) Run the k-means++ clustering algorithm you implemented in part (2) to cluster the given instances. Vary the value of kfrom 1 to 9 and compute the Silhouette coefficient for each set of clusters. Plot kin the horizontal axis and the Silhouette coefficient in the vertical axis in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2b14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff0f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bff2cbd",
   "metadata": {},
   "source": [
    "6. (10 marks) Run the Bisecting k-Means algorithm you implemented in part (3) to compute a hierarchy of clusterings that refines the initial single cluster to 9 clusters. For each s from 1 to 9, extract from the hierarchy of clusterings the clustering with sclusters and compute the Silhouette coefficient for this clustering. Plot sin the horizontal axis and the Silhouette coefficient in the vertical axis in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48055b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb41eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d412edd",
   "metadata": {},
   "source": [
    "7. (10 marks) Comparing the different clusterings you obtained in (4)-(6), discuss in which setting you obtained best clustering for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c67493",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(14)\n",
    "n = 20\n",
    "p = 2\n",
    "k = 3\n",
    "X = np.random.random((n,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "891573fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51394334, 0.77316505],\n",
       "       [0.87042769, 0.00804695],\n",
       "       [0.30973593, 0.95760374],\n",
       "       [0.51311671, 0.31828442],\n",
       "       [0.53919994, 0.22125494],\n",
       "       [0.80648136, 0.34225463],\n",
       "       [0.53888885, 0.00587379],\n",
       "       [0.67315248, 0.21002426],\n",
       "       [0.93255759, 0.37424475],\n",
       "       [0.75241892, 0.763139  ],\n",
       "       [0.87049946, 0.11011118],\n",
       "       [0.30009198, 0.47490577],\n",
       "       [0.67293672, 0.25759243],\n",
       "       [0.70115132, 0.65700006],\n",
       "       [0.18200776, 0.32206299],\n",
       "       [0.88753746, 0.08334916],\n",
       "       [0.74656412, 0.06235005],\n",
       "       [0.73148113, 0.74251135],\n",
       "       [0.40791581, 0.991383  ],\n",
       "       [0.4521373 , 0.18987854]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbcea917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, k, maxIter):\n",
    "    \n",
    "    # init centers\n",
    "    n = data.shape[0]\n",
    "    centeroid = data[np.random.choice(n, k, replace=False)]    \n",
    "    closest = np.zeros(n).astype(int)\n",
    "    \n",
    "    for iteration in range(maxIter):\n",
    "        old_closest = closest.copy()\n",
    "        \n",
    "        #  update cluster membership\n",
    "        distances = np.zeros((n,k))\n",
    "        for i in range(k):\n",
    "            distances[:,i] = ((data-centeroid[i])**2).sum(axis=1)**0.5\n",
    "        distances\n",
    "        \n",
    "        closest = np.argmin(distances, axis=1)\n",
    "        \n",
    "        #  update centers\n",
    "        for i in range(k):\n",
    "            centeroid[i, :] = data[closest == i].mean(axis=0)\n",
    "            \n",
    "#         # break if converged\n",
    "#         if all(closest == old_closest):\n",
    "#             break\n",
    "            \n",
    "    return centeroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab36f755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35882587, 0.97449337],\n",
       "       [0.39731074, 0.30527733],\n",
       "       [0.67474868, 0.73395387],\n",
       "       [0.80719418, 0.22959607],\n",
       "       [0.71862688, 0.02542359]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans(X, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kmeans(data, k):\n",
    "#     # init centers\n",
    "#     n = data.shape[0]\n",
    "#     centers = data[np.random.choice(n, k, replace=False)]    \n",
    "#     closest = np.zeros(n).astype(int)\n",
    "    \n",
    "#     while True:\n",
    "#         old_closest = closest.copy()\n",
    "        \n",
    "#         #  update cluster membership\n",
    "#         distances = np.zeros((n,k))\n",
    "#         for i in range(k):\n",
    "#             distances[:,i] = ((data-centers[i])**2).sum(axis=1)**0.5\n",
    "#         distances\n",
    "        \n",
    "#         closest = np.argmin(distances, axis=1)\n",
    "        \n",
    "#         #  update centers\n",
    "#         for i in range(k):\n",
    "#             centers[i, :] = data[closest == i].mean(axis=0)\n",
    "            \n",
    "#         # break if converged\n",
    "#         if all(closest == old_closest):\n",
    "#             break\n",
    "            \n",
    "#     return closest, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff07296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def k_means_clustering(k, dataset, max_iterations=1000):\n",
    "#     # Initialization phase\n",
    "#     cluster_representatives = dataset[np.random.choice(dataset.shape[0], k, replace=False), :]\n",
    "\n",
    "#     # Repeat assignment and optimization phases until convergence\n",
    "#     for i in range(max_iterations):\n",
    "#         # Assignment phase\n",
    "#         distances = np.sum((dataset[:, np.newaxis, :] - cluster_representatives[np.newaxis, :, :]) ** 2, axis=2)\n",
    "#         cluster_assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "#         # Optimization phase\n",
    "#         new_cluster_representatives = np.array([dataset[cluster_assignments == j].mean(axis=0) for j in range(k)])\n",
    "\n",
    "#         # Check for convergence\n",
    "#         if np.allclose(cluster_representatives, new_cluster_representatives):\n",
    "#             break\n",
    "\n",
    "#         # Update cluster representatives\n",
    "#         cluster_representatives = new_cluster_representatives\n",
    "\n",
    "#     return cluster_representatives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
